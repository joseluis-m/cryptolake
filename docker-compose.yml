# ============================================================
# CryptoLake — Docker Compose (corregido para Apache Spark oficial)
# ============================================================
# Arrancar:  docker compose up -d --build
# Parar:     docker compose down
# Resetear:  docker compose down -v
# ============================================================

x-common-env: &common-env
  MINIO_ENDPOINT: http://minio:9000
  MINIO_ACCESS_KEY: cryptolake
  MINIO_SECRET_KEY: cryptolake123
  KAFKA_BOOTSTRAP_SERVERS: kafka:29092
  ICEBERG_CATALOG_URI: http://iceberg-rest:8181
  AWS_ACCESS_KEY_ID: cryptolake
  AWS_SECRET_ACCESS_KEY: cryptolake123
  AWS_REGION: us-east-1

services:

  # ==========================================================
  # CAPA DE ALMACENAMIENTO
  # ==========================================================

  minio:
    image: minio/minio:latest
    container_name: cryptolake-minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: cryptolake
      MINIO_ROOT_PASSWORD: cryptolake123
    command: server /data --console-address ":9001"
    volumes:
      - minio-data:/data
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 10s
      timeout: 5s
      retries: 5

  minio-init:
    image: minio/mc:latest
    container_name: cryptolake-minio-init
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      mc alias set local http://minio:9000 cryptolake cryptolake123;
      mc mb local/cryptolake-bronze --ignore-existing;
      mc mb local/cryptolake-silver --ignore-existing;
      mc mb local/cryptolake-gold --ignore-existing;
      mc mb local/cryptolake-checkpoints --ignore-existing;
      echo '✅ Buckets creados';
      "

  iceberg-rest:
    image: tabulario/iceberg-rest:1.5.0
    container_name: cryptolake-iceberg-rest
    ports:
      - "8181:8181"
    environment:
      CATALOG_WAREHOUSE: s3://cryptolake-bronze/
      CATALOG_IO__IMPL: org.apache.iceberg.aws.s3.S3FileIO
      CATALOG_S3_ENDPOINT: http://minio:9000
      CATALOG_S3_PATH__STYLE__ACCESS: "true"
      AWS_ACCESS_KEY_ID: cryptolake
      AWS_SECRET_ACCESS_KEY: cryptolake123
      AWS_REGION: us-east-1
    depends_on:
      minio:
        condition: service_healthy

  # ==========================================================
  # CAPA DE STREAMING
  # ==========================================================

  kafka:
    image: confluentinc/cp-kafka:7.6.0
    container_name: cryptolake-kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,EXTERNAL://localhost:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,CONTROLLER://0.0.0.0:29093,EXTERNAL://0.0.0.0:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:29093
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk
    volumes:
      - kafka-data:/var/lib/kafka/data
    healthcheck:
      test: kafka-topics --bootstrap-server localhost:29092 --list
      interval: 10s
      timeout: 10s
      retries: 10

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: cryptolake-kafka-ui
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: cryptolake
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
    depends_on:
      kafka:
        condition: service_healthy

  # ==========================================================
  # CAPA DE PROCESAMIENTO (Apache Spark — imagen oficial)
  # ==========================================================
  #
  # La imagen oficial de Apache Spark NO tiene scripts mágicos
  # como la antigua imagen de Bitnami. Necesitamos lanzar el
  # master y el worker explícitamente con spark-class.
  #
  # spark-class es el lanzador de bajo nivel de Spark.
  # Le pasamos la clase Java que queremos ejecutar:
  #   - org.apache.spark.deploy.master.Master  → arranca el master
  #   - org.apache.spark.deploy.worker.Worker  → arranca un worker
  #
  # El master coordina, el worker ejecuta las tareas.

  spark-master:
    build:
      context: ./docker/spark
      dockerfile: Dockerfile
    image: cryptolake-spark
    container_name: cryptolake-spark-master
    ports:
      - "8082:8080"   # Spark Web UI (la imagen oficial usa 8080 internamente)
      - "7077:7077"   # Puerto del master (los workers se conectan aquí)
    environment:
      <<: *common-env
      # SPARK_MASTER_HOST le dice al master en qué hostname anunciarse.
      # Los workers usarán este nombre para conectarse.
      SPARK_MASTER_HOST: spark-master
      SPARK_MASTER_PORT: 7077
      # SPARK_NO_DAEMONIZE hace que Spark se ejecute en primer plano (foreground).
      # Sin esto, el proceso arrancaría en background y Docker pensaría que
      # terminó, matando el contenedor inmediatamente. Es el error que viste.
      SPARK_NO_DAEMONIZE: "true"
    volumes:
      - ./src:/opt/spark/work/src
    # Lanzar el master directamente con spark-class
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 10s
      timeout: 5s
      retries: 10

  spark-worker:
    build:
      context: ./docker/spark
      dockerfile: Dockerfile
    container_name: cryptolake-spark-worker
    environment:
      <<: *common-env
      SPARK_WORKER_MEMORY: 2g
      SPARK_WORKER_CORES: 2
      SPARK_NO_DAEMONIZE: "true"
      SPARK_WORKER_DIR: /tmp/spark-worker
    depends_on:
      spark-master:
        condition: service_healthy
    volumes:
      - ./src:/opt/spark/work/src
    # Lanzar el worker apuntando al master.
    # --memory y --cores limitan los recursos que este worker ofrece al cluster.
    command: >
      /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker
      spark://spark-master:7077
      --memory 2g
      --cores 2
  
  # ============================================================
  # Spark Thrift Server: Punto de entrada JDBC para dbt y SQL tools.
  # Permite ejecutar consultas SQL sobre Iceberg desde fuera de Spark.
  # Es como un "puente" entre herramientas SQL (dbt, DBeaver, etc.)
  # y el motor de procesamiento Spark.
  # ============================================================
  spark-thrift:
      build:
        context: ./docker/spark
        dockerfile: Dockerfile
      container_name: cryptolake-spark-thrift
      ports:
        - "10000:10000"
      environment:
        <<: *common-env
        SPARK_NO_DAEMONIZE: "true"
      volumes:
        - ./src:/opt/spark/work/src:ro
      depends_on:
        spark-master:
          condition: service_healthy
      command: ["/opt/spark/sbin/start-thriftserver.sh", "--master","spark://spark-master:7077", "--hiveconf", "hive.server2.thrift.port=10000", "--hiveconf", "hive.server2.thrift.bind.host=0.0.0.0", "--hiveconf", "hive.server2.authentication=NOSASL", "--conf", "spark.sql.defaultCatalog=cryptolake"]


  # ==========================================================
  # CAPA DE ORQUESTACIÓN
  # ==========================================================

  airflow-postgres:
    image: postgres:16-alpine
    container_name: cryptolake-airflow-db
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - airflow-db-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 5s
      timeout: 5s
      retries: 5

  airflow-webserver:
    build:
      context: ./docker/airflow
      dockerfile: Dockerfile
    container_name: cryptolake-airflow-webserver
    user: root
    ports:
      - "8083:8080"
    environment:
      <<: *common-env
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__WEBSERVER__SECRET_KEY: cryptolake-secret-key
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    volumes:
      - ./src/orchestration/dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - airflow-logs:/opt/airflow/logs
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      airflow-postgres:
        condition: service_healthy
    command: >
      bash -c "
      airflow db migrate &&
      airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@cryptolake.dev || true &&
      airflow webserver
      "

  airflow-scheduler:
    build:
      context: ./docker/airflow
      dockerfile: Dockerfile
    container_name: cryptolake-airflow-scheduler
    user: root
    environment:
      <<: *common-env
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__WEBSERVER__SECRET_KEY: cryptolake-secret-key
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    volumes:
      - ./src/orchestration/dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - airflow-logs:/opt/airflow/logs
      - /var/run/docker.sock:/var/run/docker.sock
    depends_on:
      airflow-postgres:
        condition: service_healthy
    command: airflow scheduler
  
  # ============================================================
  # SERVING LAYER (Fase 7)
  # ============================================================
  api:
    build:
      context: ./docker/api
      dockerfile: Dockerfile
    container_name: cryptolake-api
    ports:
      - "8000:8000"
    environment:
      <<: *common-env
      THRIFT_HOST: spark-thrift
      THRIFT_PORT: "10000"
    volumes:
      - ./src:/app/src
    depends_on:
      - spark-thrift

  dashboard:
    image: python:3.11-slim
    container_name: cryptolake-dashboard
    ports:
      - "8501:8501"
    environment:
      <<: *common-env
      API_URL: http://api:8000
    volumes:
      - ./src/serving/dashboard:/app
    command: >
      bash -c "pip install streamlit requests plotly pandas &&
      streamlit run /app/app.py --server.address 0.0.0.0"
    depends_on:
      - api

volumes:
  minio-data:
  kafka-data:
  airflow-db-data:
  airflow-logs:
